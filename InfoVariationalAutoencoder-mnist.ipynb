{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5844e620-36d3-44d8-8c6b-82265fae0b41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MMD-Variational Autoencoder\n",
    "\n",
    "The MMD-VAE is from the Info-VAE family and is another seminal progression that improves upon the traditional VAE. MMD-VAE does this by employing both mutual information maximization and the Maximum-Mean Discrepancy 'sudo' metric (discrepancy measures aren't actually metrics as they are not symmetric). The introduction od these methods overcome two of the shortcommings of the traditional estimated lower bound, particularly its ability to push the latent space far apart resulting in poor inference and its ability to learn a decoder (q(x|z)) that is unreliant on the latent space (z). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f9188-09fe-4b2b-abf9-44845a3b8665",
   "metadata": {},
   "source": [
    "## Pytorch Implementation\n",
    "\n",
    "Using pytorch and the mnist dataset.\n",
    "\n",
    "Import everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4196124-94cb-4477-ba75-ce5bfbef0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e019a-30e9-4e0f-b573-904ab3006664",
   "metadata": {},
   "source": [
    "Lets use weights and bisases. You will need an account.\n",
    "If running this on a cluster with jupyter nbconvert then you will have to add your wandb key as a environment variable in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c6f48b-ea2e-459c-9844-545d145fe94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bb5a1-6571-4885-b566-68b1e51a262c",
   "metadata": {},
   "source": [
    "Edit the below cell to setup project global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56c7cbe-0599-4073-8b05-0ed9440a4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjcoll44\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jcoll44/MMD-VAE-MNIST/runs/s0bcc3lf\" target=\"_blank\">chocolate-paper-3</a></strong> to <a href=\"https://wandb.ai/jcoll44/MMD-VAE-MNIST\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#Variables\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 18\n",
    "input_size = 28*28\n",
    "latent_size = 2\n",
    "hidden_size = 512\n",
    "model_name = \"model_z2_1.pth\"\n",
    "weights_name = \"model_weights_z2_1.pth\"\n",
    "\n",
    "wandb.init(project=\"MMD-VAE-MNIST\",\n",
    "           config={\n",
    "               \"batch_size\": batch_size,\n",
    "               \"learning_rate\": learning_rate,\n",
    "               \"dataset\": \"MNIST\",\n",
    "           })\n",
    "\n",
    "#Beta specific parameters\n",
    "Beta = 4 #the value for beta used for the experiments in the paper.\n",
    "\n",
    "\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd11111-e45a-4573-8ad1-37a096cafc0e",
   "metadata": {},
   "source": [
    "Now, let's set up our MNIST dataset. This is a simple setup and uses built in functions that can be found almost line-for-line in the pytorch quickstart guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29deb6e6-d912-4628-ba07-48d17c5a6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([32, 1, 28, 28])\n",
      "Shape of y:  torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size)\n",
    "\n",
    "#Printing data\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2d43b-7788-4361-9458-362efa849070",
   "metadata": {},
   "source": [
    "Now to create a class for the encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ea17f6-b28e-402e-a78b-917d10b1c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNeuralNetwork(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.network = torch.nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class DecoderNeuralNetwork(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.network = torch.nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),      \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d8121-4b6d-4f3b-823e-a7a9f8f173c7",
   "metadata": {},
   "source": [
    "Now to instantiate our encoder and decoder classes to create a variational autoencoder.\n",
    "Up until here it is pretty easy to follow. This next bit is where the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5799603c-277a-4417-be90-323e21884c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderNeuralNetwork(input_size, hidden_size)\n",
    "        self.decoder = DecoderNeuralNetwork(latent_size, hidden_size, input_size)\n",
    "        \n",
    "        # Parameters for decoding the output of the encoder\n",
    "        self.fc_mu = nn.Linear(hidden_size, latent_size) #mu is the mean\n",
    "        self.fc_var = nn.Linear(hidden_size, latent_size) #var is the variance\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "        # measure prob of seeing image under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "        return log_pxz.sum(-1)\n",
    "    \n",
    "    def compute_kernel(self, x, y):\n",
    "        x_size = x.size(0)\n",
    "        y_size = y.size(0)\n",
    "        dim = x.size(1)\n",
    "        x = torch.unsqueeze(x,1) # (x_size, 1, dim) Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "        y = torch.unsqueeze(y,0) # (1, y_size, dim) Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "        tiled_x = x.expand(x_size, y_size, dim)\n",
    "        tiled_y = y.expand(x_size, y_size, dim)\n",
    "        dim = torch.tensor([float(dim)]).to(device)\n",
    "        kernel_input = torch.mean(torch.pow((tiled_x - tiled_y),2), dim =2)/dim\n",
    "        return torch.exp(-kernel_input) # (x_size, y_size)\n",
    "        \n",
    "\n",
    "    def mmd_divergence(self, x, y):\n",
    "        #This is the MMD computation\n",
    "        x_kernel = self.compute_kernel(x, x)\n",
    "        y_kernel = self.compute_kernel(y, y)\n",
    "        xy_kernel = self.compute_kernel(x, y)\n",
    "        mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "\n",
    "        return mmd \n",
    "    \n",
    "    def encode(self, x):\n",
    "        #Encoder otherwise known as q. Pass x through it.\n",
    "        encoded_x = self.encoder(x)\n",
    "        \n",
    "        #Use the encoding to find the mean and variance\n",
    "        mu, log_var = self.fc_mu(encoded_x), self.fc_var(encoded_x)\n",
    "        \n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "        \n",
    "        return z, mu, std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #Encode x to find z\n",
    "        z, mu, std = self.encode(x)\n",
    "        \n",
    "        # decode the latent space, otherwise known as the function p.\n",
    "        # x_hat because this is the new x\n",
    "        x_hat = self.decode(z)\n",
    "        \n",
    "        # Calculate the ELBO loss. Remember the two parts....1 Reconstruction Loss and 2 KL divergence\n",
    "        # 1 reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "        recon_loss = torch.mean(recon_loss*-1)\n",
    "        \n",
    "        # 2 MMD divergence\n",
    "        #first sample from the target distribution - \n",
    "        #we sample 200 random numbers from a guassian distribution mean:0 var:1\n",
    "        target_samples = Variable(torch.randn(200, self.latent_size),\n",
    "                                requires_grad=False).to(device)\n",
    "        mmd = self.mmd_divergence(target_samples, z).mean()\n",
    "        \n",
    "        #Evidence lower bound\n",
    "        elbo = recon_loss + mmd\n",
    "        elbo = elbo.mean()\n",
    "        \n",
    "        return elbo, recon_loss, mmd, x_hat, z\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8670ae-f3f3-4ba1-91af-4d60b37b25e7",
   "metadata": {},
   "source": [
    "Now that we have the VAE class we can go about setting up training and testing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94230316-153c-4974-8e4e-565c12c4649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): EncoderNeuralNetwork(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): DecoderNeuralNetwork(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=784, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (fc_var): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VAE(input_size = input_size, hidden_size = hidden_size, latent_size = latent_size).to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(dataloader, model, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    for (image, _) in dataloader:\n",
    "    # for batch, (X, y) in enumerate(dataloader):\n",
    "    \n",
    "        # Compute prediction and loss\n",
    "        image = image.reshape(-1, 28*28)\n",
    "        image = image.to(device)\n",
    "        # X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        elbo, recon_loss, mmd,  x_hat, z = model(image)\n",
    "        loss = elbo\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss= 0\n",
    "    mmd_loss= 0\n",
    "    recon_loss= 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            image = X.reshape(-1, 28*28)\n",
    "            image = image.to(device)\n",
    "            elbo, recon, mmd, x_hat, z = model(image)\n",
    "            test_loss += elbo\n",
    "            mmd_loss += mmd\n",
    "            recon_loss += recon\n",
    "            \n",
    "    \n",
    "    test_loss_avg = test_loss/num_batches\n",
    "    mmd_loss /= num_batches\n",
    "    recon_loss /= num_batches\n",
    "    wandb.log({\"loss\": test_loss_avg, \n",
    "               \"elbo\": test_loss, \n",
    "               \"mmd\": mmd_loss,\n",
    "               \"reconstruction\": recon_loss\n",
    "              })\n",
    "    wandb.watch(model)\n",
    "    return test_loss_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83729a53-a78b-4a75-8dd4-51d380c75fbb",
   "metadata": {},
   "source": [
    "Train our model and use the test dataset to plot the loss and other significant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20e9b26-d13f-437a-95d6-22cfc2c1fa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/jcoll44/MMD-VAE-MNIST/runs/s0bcc3lf?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7f9c60c73610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Avg loss: 599.982483 \n",
      "\n",
      "Done!\n",
      "GPU time 212.2602 seconds\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "#Timing the hardware difference\n",
    "tic = time.perf_counter()\n",
    "\n",
    "for t in range(epochs):\n",
    "    train(train_dataloader, model, optimizer)\n",
    "    test_loss = test(test_dataloader, model)\n",
    "    if t%20==0:\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")    \n",
    "        print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "print(\"Done!\")\n",
    "\n",
    "toc = time.perf_counter()\n",
    "if {device} == \"cpu\":\n",
    "    print(f\"CPU time {toc - tic:0.4f} seconds\")\n",
    "else:\n",
    "    print(f\"GPU time {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aaccd3-2b3e-4bf4-bdc0-e2345d3fdd06",
   "metadata": {},
   "source": [
    "Now that we have trained our model we should save the model and the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bb403d-5433-455e-81fc-830bc2bc28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name)\n",
    "torch.save(model.state_dict(), weights_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452314a-9795-4890-be76-59c4b6c4c26e",
   "metadata": {},
   "source": [
    "## Plotting and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fada54-da6b-4b42-9748-bbef2edaac69",
   "metadata": {},
   "source": [
    "Lets begin our visualisation by plotting some randomly chosen numbers before reconstruction and after reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2814d1e8-2297-4abc-be0a-37a1ee7e0bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "cols, rows = 6, 2\n",
    "for i in range(1, cols +1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    image = img.reshape(-1, 28*28)\n",
    "    image = image.to(device)\n",
    "    elbo, recon, mmd, x_hat, z = model(image)\n",
    "    pred = x_hat.to(\"cpu\")\n",
    "    pred = pred.detach().numpy()\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(\"Real\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    figure.add_subplot(rows, cols, i+cols)\n",
    "    plt.title(\"Decoded\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(pred.reshape(1,28,28).transpose(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd6ad1-c8ed-48e6-abef-bd7466d8bd4f",
   "metadata": {},
   "source": [
    "Now lets investigate the latent space further. The plot below shows the latent space and where different MNIST numbers are located within it. They should be clustered by their number and centrally located around 0 as we directed them to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f0be1-958c-4b75-8aad-8886c49c9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent(model, dataloader, num_batches=100):\n",
    "    for (image, y) in dataloader:\n",
    "        image = image.reshape(-1, 28*28)\n",
    "        image = image.to(device)\n",
    "        elbo, recon, mmd, x_hat, z = model(image)\n",
    "        z = z.to('cpu').detach().numpy()\n",
    "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n",
    "\n",
    "    plt.colorbar()\n",
    "            \n",
    "plot_latent(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee3f8e-4594-4507-babe-4d378794a766",
   "metadata": {},
   "source": [
    "Now lets do a linear interpolation between all the number, i.e. 1->2, 2->3 etc.\n",
    "We can do this by taking the latent space of 2 numbers (e.g. 1 and 2) and calculating the latent vector halfway between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8b555-27c5-4418-80a2-82f78296c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_array = []\n",
    "figure = plt.figure(figsize=(25, 12))\n",
    "cols, rows = 10 , 3\n",
    "\n",
    "for k in range(10):\n",
    "    for (image, y) in training_data:\n",
    "        if y==k:\n",
    "            number_array.append(image)\n",
    "            break\n",
    "    \n",
    "for l in range(1,10):\n",
    "    number_a = number_array[l-1].reshape(-1, 28*28)\n",
    "    number_a = number_a.to(device)\n",
    "    elbo, recon, mmd, x_hat_a, z_a = model(number_a)\n",
    "    \n",
    "    number_b = number_array[l].reshape(-1, 28*28)\n",
    "    number_b = number_b.to(device)\n",
    "    elbo, recon, mmd, x_hat_b, z_b = model(number_b)\n",
    "    \n",
    "    figure.add_subplot(rows, cols, l)\n",
    "    plt.title(str(l-1))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(x_hat_a.to(\"cpu\").detach().numpy().reshape(1,28,28).transpose(1, 2, 0), cmap=\"gray\")\n",
    "    \n",
    "    figure.add_subplot(rows, cols, l+(cols*2))\n",
    "    plt.title(str(l))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(x_hat_b.to(\"cpu\").detach().numpy().reshape(1,28,28).transpose(1, 2, 0), cmap=\"gray\")\n",
    "    \n",
    "    z_c = z_a*0.5 + z_b*0.5\n",
    "    number_c = z_c.to(device)\n",
    "    x_hat = model.decode(number_c)\n",
    "    figure.add_subplot(rows, cols, l+(cols))\n",
    "    plt.title(str(l-1)+\" merged with \"+str(l))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(x_hat.to(\"cpu\").detach().numpy().reshape(1,28,28).transpose(1, 2, 0), cmap=\"gray\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17258f5c-6366-43ee-8952-e3e46ab54146",
   "metadata": {},
   "source": [
    "For our last visualisation lets produce a square \"walk\" around the latent space. This is similar to the plot_latent() function above although with images rather than a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f317d0-bd4a-47a4-a2a0-c60558c0b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed(autoencoder, r0=(-6, 5), r1=(-6, 5), n=12):\n",
    "    w = 28\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(device)\n",
    "            x_hat = autoencoder.decoder(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    plt.imshow(img, extent=[*r0, *r1], cmap=\"gray\")\n",
    "    \n",
    "plot_reconstructed(model2, (-6, 5), (-6, 5), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f64c8-e60f-454c-a401-a169ce45a822",
   "metadata": {},
   "source": [
    "If we wanted to reload the model at a latter date we could do so with the code below. Just make sure to run the classes up above first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9846ec-3ab3-4e93-b855-b94b241d095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load(model_name)\n",
    "model.load_state_dict(torch.load(weights_name))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
